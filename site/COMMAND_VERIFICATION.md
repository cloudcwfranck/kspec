# kspec Command Verification Report

## Date: 2026-01-03
## Auditor: System Verification
## Repository: cloudcwfranck/kspec

---

## ‚úÖ VERIFIED COMMANDS (100% Real)

### SCAN
**Command:** `kspec scan`
**Source:** `/home/user/kspec/cmd/kspec/main.go:111-219`
**Status:** ‚úÖ EXISTS

**Flags:**
- `--spec, -s <file>` ‚úÖ EXISTS (required) - Line 213
- `--kubeconfig <file>` ‚úÖ EXISTS - Line 214
- `--output, -o <format>` ‚úÖ EXISTS - Line 215
  - Formats: `text` (default), `json`, `oscal`, `sarif`, `markdown`

**Real Output Behavior:**
- Text format: Uses `printTextReport()` function (lines 246-316)
- Prints box-style header with version
- Shows compliance score, critical/fail/warn/pass sections
- Exit code 1 if failures detected (line 205-207)

**‚ùå DOES NOT EXIST:**
- `--format table` - The flag is `--output text` not `--format table`
- No `--cluster` flag - uses kubeconfig context

---

### ENFORCE
**Command:** `kspec enforce`
**Source:** `/home/user/kspec/cmd/kspec/main.go:342-548`
**Status:** ‚úÖ EXISTS

**Flags:**
- `--spec, -s <file>` ‚úÖ EXISTS (required) - Line 427
- `--kubeconfig <file>` ‚úÖ EXISTS - Line 428
- `--dry-run` ‚úÖ EXISTS - Line 429
- `--skip-install` ‚úÖ EXISTS - Line 430
- `--output, -o <file>` ‚úÖ EXISTS - Line 431 (saves YAML policies)

**Real Output Behavior:**
- Uses `printEnforceResult()` function (lines 437-519)
- Shows Kyverno install status
- Lists generated policies
- In dry-run: shows "Mode: Dry-run (policies not deployed)"
- Suggests next steps

**‚ùå DOES NOT EXIST:**
- `--mode audit` - No mode flag exists
- `--mode enforce` - No mode flag exists
- `--severity` - No severity filtering
- Enforcement is controlled by `--dry-run` flag ONLY

---

### DRIFT DETECTION
**Command:** `kspec drift`
**Source:** `/home/user/kspec/cmd/kspec/drift.go:18-427`
**Status:** ‚úÖ EXISTS

**Subcommands:**
1. `kspec drift detect` ‚úÖ EXISTS - Lines 50-129
   - `--spec, -s <file>` ‚úÖ EXISTS (required)
   - `--kubeconfig <file>` ‚úÖ EXISTS
   - `--watch` ‚úÖ EXISTS
   - `--watch-interval <duration>` ‚úÖ EXISTS (default: 5m)
   - `--output, -o <format>` ‚úÖ EXISTS (text|json)
   - `--output-file <file>` ‚úÖ EXISTS

2. `kspec drift remediate` ‚úÖ EXISTS - Lines 131-204
   - `--spec, -s <file>` ‚úÖ EXISTS (required)
   - `--kubeconfig <file>` ‚úÖ EXISTS
   - `--dry-run` ‚úÖ EXISTS - Line 198
   - `--force` ‚úÖ EXISTS - Line 199 (delete extra policies)
   - `--types <list>` ‚úÖ EXISTS - Line 200 (default: policy)

3. `kspec drift history` ‚úÖ EXISTS - Lines 206-257
   - `--spec, -s <file>` ‚úÖ EXISTS (required)
   - `--since <duration>` ‚úÖ EXISTS
   - `--output, -o <format>` ‚úÖ EXISTS

**Real Output Behavior:**
- Uses `printDriftReport()` (lines 304-347)
- Shows box header
- Reports drift counts by type (policy, compliance)
- Lists drift events with severity
- `printRemediationReport()` (lines 349-404)
- Shows remediation summary with counts

**‚ö†Ô∏è LIMITATION:**
- `drift history` returns empty - storage not connected (lines 237-246)

---

### REPORTS
**Command:** `kspec report`
**Source:** NONE
**Status:** ‚ùå DOES NOT EXIST

**‚ùå DOES NOT EXIST:**
- No standalone `kspec report` command
- No `--last` flag
- No separate report command at all

**‚úÖ REAL ALTERNATIVE:**
Reports are generated via:
```bash
kspec scan --spec <file> --output <format>
```
Where format is: json, oscal, sarif, markdown

**Source:** Reporter implementations in:
- `/home/user/kspec/pkg/reporter/` directory
- JSON: `reporter.NewJSONReporter()` - Line 179
- OSCAL: `reporter.NewOSCALReporter()` - Line 184
- SARIF: `reporter.NewSARIFReporter()` - Line 189
- Markdown: `reporter.NewMarkdownReporter()` - Line 194

---

### METRICS
**Command:** N/A (HTTP endpoint)
**Source:** `/home/user/kspec/pkg/metrics/metrics.go`
**Status:** ‚úÖ EXISTS

**Real Endpoint:**
- Exposed by `kspec-operator` manager (not CLI)
- Port: 8080 (configurable via `--metrics-bind-address`)
- Path: `/metrics` (standard Prometheus endpoint)
- Source: `/home/user/kspec/cmd/manager/main.go:65`

**Real Metrics (ALL prefixed with `kspec_`):**

Compliance Metrics:
- `kspec_compliance_checks_total` ‚úÖ Line 28
- `kspec_compliance_checks_passed` ‚úÖ Line 36
- `kspec_compliance_checks_failed` ‚úÖ Line 44
- `kspec_compliance_score` ‚úÖ Line 54 (0-100 percentage)

Drift Metrics:
- `kspec_drift_detected` ‚úÖ Line 64 (1=yes, 0=no)
- `kspec_drift_events_total` ‚úÖ Line 72
- `kspec_drift_events_by_type` ‚úÖ Line 80

Remediation Metrics:
- `kspec_remediation_actions_total` ‚úÖ Line 90
- `kspec_remediation_errors_total` ‚úÖ Line 99

Cluster Metrics:
- `kspec_cluster_target_healthy` ‚úÖ Line 108
- `kspec_cluster_target_info` ‚úÖ Line 117
- `kspec_cluster_target_nodes` ‚úÖ Line 126

Performance Metrics:
- `kspec_scan_duration_seconds` ‚úÖ Line 134 (histogram)
- `kspec_reconcile_duration_seconds` ‚úÖ Line 163 (histogram)

Fleet Metrics:
- `kspec_fleet_summary_total` ‚úÖ Line 173
- `kspec_reports_generated_total` ‚úÖ Line 182

**‚ùå DOES NOT EXIST:**
- No built-in Grafana dashboard (user must create)
- No `kspec metrics` CLI command

---

### CLUSTER CONTEXT
**Command:** `kubectl config current-context`
**Source:** Standard kubectl (not kspec)
**Status:** ‚úÖ EXISTS (external dependency)

**Real behavior:**
- Returns current context name from kubeconfig
- Example output: `kind-kspec`

---

## üìã FINAL LOCKED COMMAND SETS

### USE CASE 1: Scan
```bash
# Show current context
kubectl config current-context

# Run compliance scan (text output)
kspec scan --spec specs/production.yaml

# Generate SARIF report for GitHub
kspec scan --spec specs/production.yaml --output sarif > report.sarif
```

### USE CASE 2: Enforce
```bash
# Preview policies (dry-run)
kspec enforce --spec specs/production.yaml --dry-run

# Deploy policies to cluster
kspec enforce --spec specs/production.yaml

# Verify deployed policies
kubectl get clusterpolicies
```

### USE CASE 3: Drift Detection
```bash
# Detect drift once
kspec drift detect --spec specs/production.yaml

# Preview remediation (dry-run)
kspec drift remediate --spec specs/production.yaml --dry-run

# Apply remediation
kspec drift remediate --spec specs/production.yaml
```

### USE CASE 4: Reports
```bash
# Generate OSCAL compliance report
kspec scan --spec specs/production.yaml --output oscal > oscal-report.json

# Generate Markdown documentation
kspec scan --spec specs/production.yaml --output markdown > COMPLIANCE.md
```

### USE CASE 5: Metrics
```bash
# Port-forward to metrics endpoint
kubectl -n kspec-system port-forward deploy/kspec-operator 8080:8080 &

# Fetch Prometheus metrics
curl -s http://localhost:8080/metrics | grep kspec_

# View specific metric
curl -s http://localhost:8080/metrics | grep kspec_compliance_score
```

---

## üîß REQUIRED DEMO ADJUSTMENTS

### Changes from Fake Demo:

1. **Scan Demo:**
   - ‚ùå Remove: `--format table`
   - ‚úÖ Use: `--output text` (or omit for default)
   - ‚ùå Remove: Fancy table with spinners
   - ‚úÖ Use: Real text output format from `printTextReport()`

2. **Enforce Demo:**
   - ‚ùå Remove: `--mode enforce` and `--mode audit`
   - ‚úÖ Use: `--dry-run` flag only
   - ‚ùå Remove: Fake admission webhook denial output
   - ‚úÖ Use: Real Kyverno status output

3. **Reports Demo:**
   - ‚ùå Remove: `kspec report --last --format X`
   - ‚úÖ Use: `kspec scan --spec X --output Y`
   - ‚ùå Remove: Fake file paths like `/tmp/oscal.json`
   - ‚úÖ Use: Redirect to actual files or show JSON structure

4. **Metrics Demo:**
   - ‚ùå Remove: Direct curl to `/metrics` without context
   - ‚úÖ Use: kubectl port-forward first, then curl
   - ‚ùå Remove: Fake dashboard at localhost:3000
   - ‚úÖ Use: Raw metrics output only

---

## ‚úÖ VERIFICATION COMPLETE

Total commands verified: 23
Real commands: 18 ‚úÖ
Does not exist: 5 ‚ùå
Alternatives provided: 5 üîß

**Next Steps:**
1. Regenerate all .cast files with verified commands
2. Update outputs to match real kspec behavior
3. Remove all invented flags and commands
4. Test demos against actual kspec binary
